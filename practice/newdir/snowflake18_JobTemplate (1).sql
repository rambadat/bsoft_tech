Snowflake Job Requirement Template
==================================
Key Responsibilities
--------------------
-Develop complex SQL queries for analytics, reporting, and data transformation.
-Build/Maintain ELT/ETL pipelines using Snowflake-native capabilities and external tools like ADF or Airflow.
-Mandatory expertise in Snowflake and dbt (data build tool) along with strong skills in Data Warehousing, Data Modeling, and Data Engineering.
-Develop and optimize dbt models, transformations, and data workflows for efficient analytics
-Implement CDC (Change Data Capture) and real-time data processing solutions
-Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.
-Apply dimensional modeling techniques (Star/Snowflake schemas) to support BI and analytics.
-Optimize performance and manage compute costs through profiling and tuning.
-Manage Snowflake objects including tables, views, materialized views, streams, tasks, UDFs, and stored procedures.
-Ensure data quality, governance, and lineage across the data lifecycle.
-Troubleshoot issues related to data ingestion, transformation, and query performance.
-Stay up-to-date with Snowflake features like Time Travel, Zero Copy Cloning, Search Optimization, and CDC via Streams/Tasks.
-Hands on knowledge with the methods to identify, collect, manipulate, transform, normalize, clean, and validate data, star schema, normalization / denormalization, dimensions, aggregations etc,

Required Skills
---------------
Advanced SQL: Joins, CTEs, window functions, recursive queries, analytical functions.
Snowflake Architecture: Virtual warehouses, micro-partitions, clustering, scaling, caching.
Data Modeling: Star/Snowflake schemas, normalization/denormalization strategies.
*Performance Tuning: Query optimization, result caching, warehouse sizing.
*ETL/ELT Development: Using Snowflake-native features and orchestration tools like ADF or Airflow.
Stored Procedures & Scripting: Experience in SQL and JavaScript-based procedures and functions within Snowflake.( snowflake scripting)

Preferred Experience & Tools
----------------------------
Azure Data Factory (ADF): Pipelines, triggers, linked services, and integration with ADLS Gen2.
Programming Skills: Python or PySpark for data transformation and automation.
Snowpipe & Streams/Tasks: Real-time ingestion and Change Data Capture (CDC).
*Data Security: Implementation of row-level security, masking, and encryption.
DevOps Practices: Familiarity with Git, CI/CD pipelines, and Terraform (basic level).
